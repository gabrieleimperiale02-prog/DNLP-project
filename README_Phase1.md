# Deep NLP Project - Phase 1

## Prompt-Based Abstractive Summarization with Semantic Coverage Control


## ğŸ“ Repository Structure

```
â”œâ”€â”€ Deep_NLP_Phase1.ipynb    # Main notebook for Phase 1
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ data/                     # Generated data files
â”‚   â”œâ”€â”€ validation_samples.json
â”‚   â”œâ”€â”€ ground_truth_analysis.json
â”‚   â”œâ”€â”€ extracted_phrases.json
â”‚   â”œâ”€â”€ grouped_phrases.json
â”‚   â”œâ”€â”€ grouped_phrases_improved.json
â”‚   â”œâ”€â”€ extraction_stats.json
â”‚   â””â”€â”€ extraction_stats_improved.json
â””â”€â”€ results/                  # Analysis results
```

---

## ğŸ¯ Phase 1 Objectives

Phase 1 focuses on **data preparation and semantic extraction pipeline**:

| Task | Description | Status |
|------|-------------|--------|
| Data Loading | Load CNN/DailyMail validation set | âœ… |
| Ground Truth Analysis | Analyze coverage in reference summaries | âœ… |
| Phrase Extraction | Implement SigExt-based extraction | âœ… |
| Semantic Grouping | Group phrases into WHO/WHAT/WHEN/WHERE/NUMERIC | âœ… |
| Improved Extraction | Fix WHAT extraction gap (18% â†’ 100%) | âœ… |
| Statistics | Compute extraction rates per category | âœ… |

---

## ğŸ”¬ Methodology

### 1. Dataset
- **CNN/DailyMail** dataset (validation split)
- 200 samples for development/testing
- Articles: avg ~3000 characters
- Highlights: avg ~300 characters (reference summaries)

### 2. Phrase Extraction (SigExt)
We use spaCy for:
- **Named Entity Recognition (NER)**: PERSON, ORG, GPE, DATE, MONEY, etc.
- **Noun Chunks**: Multi-word expressions
- **Verb Phrases**: ROOT verb + direct object

### 3. Semantic Grouping
Extracted phrases are mapped to semantic categories:

| Category | Entity Types | Example |
|----------|-------------|---------|
| WHO | PERSON, ORG, NORP | "President Biden", "Google" |
| WHAT | EVENT, verb phrases | "announced deal", "investigation" |
| WHEN | DATE, TIME | "Monday", "2024" |
| WHERE | GPE, LOC, FAC | "New York", "hospital" |
| NUMERIC | MONEY, PERCENT, CARDINAL | "$5 million", "50%" |

### 4. Improved WHAT Extraction
The baseline SigExt had poor WHAT extraction (18%). We improved it by:
- Extracting verb + object patterns (not just ROOT verbs)
- Adding phrasal verbs (verb + particle)
- Including passive constructions
- Detecting event-related noun phrases

**Result: WHAT extraction improved from 18% â†’ 100%**

---

## ğŸ“Š Phase 1 Results

### Ground Truth Coverage Analysis
Category presence in reference summaries:

| Category | % of Documents |
|----------|---------------|
| WHO | 95.5% |
| WHAT | 98.0% |
| WHEN | 54.0% |
| WHERE | 73.5% |
| NUMERIC | 67.0% |

### Extraction Statistics

| Category | Original | Improved | Change |
|----------|----------|----------|--------|
| WHO | 99.5% | 99.5% | â€” |
| **WHAT** | **18.0%** | **100.0%** | **+82%** âœ… |
| WHEN | 98.0% | 98.0% | â€” |
| WHERE | 93.0% | 93.5% | +0.5% |
| NUMERIC | 89.0% | 90.0% | +1.0% |

